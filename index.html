<!DOCTYPE html>
<html lang="en" xmlns="http://www.w3.org/1999/html">

<head>
  <meta charset="utf-8">
  <title>Bias @ SIGIR2024 - International Workshop on Algorithmic Bias in Search and Recommendation</title>
  <meta content="width=device-width, initial-scale=1.0" name="viewport">
  <meta content="" name="keywords">
  <meta content="" name="description">

  <!-- Favicons -->
  <link href="img/favicon.png" rel="icon">
  <link href="img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,700,700i|Raleway:300,400,500,700,800" rel="stylesheet">

  <!-- Bootstrap CSS File -->
  <link href="lib/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Libraries CSS Files -->
  <link href="lib/font-awesome/css/font-awesome.min.css" rel="stylesheet">
  <link href="lib/animate/animate.min.css" rel="stylesheet">
  <link href="lib/venobox/venobox.css" rel="stylesheet">
  <link href="lib/owlcarousel/assets/owl.carousel.min.css" rel="stylesheet">

  <!-- Main Stylesheet File -->
  <link href="css/style.css" rel="stylesheet">

</head>

<body>

  <!--==========================
    Header
  ============================-->
  <header id="header">
    <div class="container">

      <div id="logo" class="pull-left">
        <h1><a href="#main">BIAS 2024</a></h1>
      </div>

      <nav id="nav-menu-container">
        <ul class="nav-menu">
          <li><a href="#aims">Scope</a></li>
          <li><a href="#topics">Topics</a></li>
          <li><a href="#dates">Important Dates</a></li>
          <li><a href="#submission">Submission</a></li>
          <li><a href="#keynote">Keynotes</a></li>
          <li><a href="#program">Program</a></li>
          <li><a href="#committee">Organization</a></li>
          <li><a href="#attending">Register</a></li>
          <li><a href="#editions">Editions</a></li>
          <li><a href="#contacts">Contacts</a></li>
        </ul>
      </nav><!-- #nav-menu-container -->
    </div>
  </header><!-- #header -->

  <!--==========================
    Intro Section
  ============================-->
  <section id="intro">
    <div class="intro-container wow fadeIn">
      <h1 class="mb-4 pb-0">International Workshop on <br/> Algorithmic Bias in Search and Recommendation</h1>
      <p class="mb-4 pb-0">to be held as part of the <u><a href="https://sigir-2024.github.io" target="_blank">47th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2024)</a></u></p>
      <p class="mb-4 pb-0">18 July 2024 - Washington D.C., USA <!--(with support for remote attendance)--></p>
    </div>
  </section>

  <main id="main">

    <!--==========================
    Aims and Scope Section
    ============================-->
    <section id="aims" class="wow fadeInUp">

      <div class="container-fluid">
        <div class="section-header">
          <h2>Workshop Aims and Scope</h2>

          <!--<p>Creating efficient and effective <strong>search and recommendation algorithms</strong> has been the main objective of industry practitioners and academic researchers over the years.
             However, recent research has shown how these algorithms trained on historical data lead to models that might <strong>exacerbate existing biases</strong> and generate potentially
             negative outcomes. Defining, assessing and mitigating these biases throughout experimental pipelines is a primary step for devising search and recommendation algorithms that can be
             <strong>responsibly deployed</strong> in real-world applications. This workshop aims to collect novel contributions in this field and offer a common ground for interested researchers and practitioners.</p>-->

            <p> The goal is hence to favor a <strong>community-wide dialogue on new research perspectives</strong> through a workshop having the following objectives: </p>
            <ul>
              <li>Increase awareness of the algorithmic bias problem in IR.</li>
              <li>Identify dimensions influenced by algorithmic bias in IR.</li>
              <li>Solicit contributions addressing algorithmic bias in IR. </li>
              <li>Gain insights into recent advances and open issues in IR.</li>
              <li>Familiarize the IR community with current field practices.</li>
              <li>Uncover gaps in academic and industry research in IR.</li>
            </ul>
        </div>
      </div>

    </section>

    <!--==========================
    Topics Section
    ============================-->
    <section id="topics" class="wow fadeInUp section-with-bg">

      <div class="container-fluid">
        <div class="section-header">
          <h2>Workshop Topics</h2>
          <p>The workshop welcomes contributions on topics about algorithmic bias in search and recommendation, focused (but not limited) to:</p>
          <ul>
            <li><strong>Data Set Collection and Preparation</strong>:
               <ul>
                  <li>Studying the interplay between bias and imbalanced data.</li>
                  <li>Designing methods for dealing with imbalances in data.</li>
                  <li>Creating data pipelines for less biased data sets.</li>
                  <li>Collecting data sets for the analysis of biased situations.</li>
                  <li>Designing protocols for data sets tailored to bias analysis.</li>
              </ul>
            </li>
            <li><strong>Countermeasure Design and Development</strong>:
               <ul>
                  <li>Formalizing and operationalizing bias concepts.</li>
                  <li>Conducting exploratory analysis that uncover bias.</li>
                  <li>Designing treatments that mitigate biases.</li>
                  <li>Devising methods for explaining biases. </li>
                  <li>Studying causal and counterfactual reasoning for bias.</li>
              </ul>
            </li>
            <li><strong>Evaluation Protocol and Metric Formulation</strong>:
               <ul>
                  <li>Performing auditing studies with respect to bias. </li>
                  <li>Conducting  experimental studies on bias. </li>
                  <li>Defining objective metrics that consider bias.</li>
                  <li>Formulating bias-aware protocols to evaluate models. </li>
				          <li>Evaluating mitigation strategies in unexplored domains.</li>
                  <li>Comparative studies of existing evaluation protocols. </li>
                  <li>Analysing scalability issues of debiasing methods.</li>
              </ul>
            </li>
            <li><strong>Case Study Exploration</strong>:
               <ul>
                  <li>E-commerce platforms.</li>
                  <li>Educational environments.</li>
                  <li>Entertainment websites.</li>
                  <li>Healthcare systems.</li>
                  <li>Social media.</li>
                  <li>News platforms.</li>
                  <li>Digital libraries.</li>
                  <li>Job portals.</li>
                  <li>Dating platforms.</li>
              </ul>
            </li>
          </ul>

        </div>
      </div>

    </section>

    <!--==========================
    Important Dates Section
    ============================-->
    <section id="dates" class="wow fadeInUp">

      <div class="container-fluid">
        <div class="section-header">
          <h2>Important Dates</h2>
          <ul>
            <li>Submissions: <strong> <del>April 25, 2024</del> <font color="red"> May 2, 2024.</font></strong></li>
            <li>Notifications: June 6, 2024.</li>
            <li>Camera-Ready: June 20, 2024. </li>
            <li>Workshop: July 18, 2024  - Washington D.C., USA. </li>
          </ul>
          <p>All deadlines are 11:59pm, AoE time (Anywhere on Earth).</p>
        </div>
      </div>

    </section>

    <!--==========================
    Submission Details Section
    ============================-->
    <section id="submission" class="wow fadeInUp section-with-bg">

      <div class="container-fluid">
        <div class="section-header">
          <h2>Submission Details</h2>
            
          <p>We invite authors to submit unpublished original papers, written in English. Submitted papers should not have been previously published or accepted for publication in substantially similar form in any peer-reviewed venue, such as journals, conferences, or workshops.</p>
          <p> The authors should consult the <a href="https://resource-cms.springernature.com/springer-cms/rest/v1/content/19242230/data/v13" target="_blank">Springer’s authors’ guidelines </a> 
              and use their proceedings templates, either <a href="https://resource-cms.springernature.com/springer-cms/rest/v1/content/19238648/data/v8" target="_blank">LaTeX</a> 
              or <a href="https://resource-cms.springernature.com/springer-cms/rest/v1/content/19238706/data/v3" target="_blank"> Word</a>.</p>
          <p>Papers should be submitted as PDF files to Easychair at <a href="https://easychair.org/conferences/?conf=bias2024" target="_blank">https://easychair.org/conferences/?conf=bias2024</a>.</p>
          <p>We will consider three different submission types:</p>
          <ul>
            <li><strong>Full papers (12 pages) </strong> should be clearly placed with respect to the state of the art and state the contribution of the proposal
                in the domain of application, even if presenting preliminary results. In particular, research papers should describe the methodology
                in detail, experiments should be repeatable, and a comparison with the existing approaches in the literature should be made. </li>
            <li><strong>Reproducibility papers (12 pages) </strong> should repeat prior experiments using the original source code and datasets to show how, why, and when the methods
                work or not (replicability papers) or should repeat prior experiments, preferably using the original source code, in new contexts (e.g., different domains and datasets,
                different evaluation and metrics) to further generalize and validate or not previous work (reproducibility papers).</li>
            <li><strong> Short paper (6 pages) or position papers (4 pages)  </strong> should introduce new point of views in the workshop topics or summarize the experience of a
                group in the field. Practice and experience reports should present in detail real-world scenarios in which search and recommender
                systems are exploited. </li>
          </ul>

          <p>Submissions should not exceed the indicated number of pages, including any diagrams and references. </p>

          <p>All submissions will go through a <strong>double-blind</strong> review process and be reviewed by at least three reviewers on the basis of relevance for the workshop, novelty/originality, significance,
             technical quality and correctness, quality and clarity of presentation, quality of references and reproducibility.</p>
          <p>Submitted papers will be rejected without review in case they are not properly anonymized, do not comply with the template, or do not follow the above guidelines.</p>
          <p>The accepted papers and the material generated during the meeting will be available on the workshop website. It is planned to send the workshop proceedings for consideration for inclusion as a <strong>Springer's Communications in Computer and Information Science (CCIS) revised post-proceedings volume</strong>, indexed on Google Scholar, DBLP and Scopus. The authors of selected papers may be invited to submit an extended version in a journal special issue.</p>

          <p>Please be aware that at least one author per paper needs to register and attend the workshop to present the work.</p>
          <p>We expect authors, the program committee, and the organizing committee to adhere to the <a href="https://www.acm.org/special-interest-groups/volunteer-resources/acm-conflict-of-interest-policy" target="_blank">ACM’s Conflict of Interest Policy </a> and the <a href="https://www.acm.org/code-of-ethics" target="_blank">ACM’s Code of Ethics and Professional Conduct</a>. </p>


        </div>
      </div>

    </section>

     <!--==========================
    Keynote Section
    ============================-->
    <section id="keynote" class="wow fadeInUp">

      <div class="container-fluid">
        <div class="section-header">
          <h2>Keynote Speakers</h2>

            </br>

		      <p style="text-align: center;"><img src="./img/bmitra.jpg" class="img-rounded" alt="Bhaskar Mitra" style=" width: 30%;"></p>

          <p style="text-align: center;">Dr. <strong><a href=" " target="_blank">Bhaskar Mitra</a> <br> Microsoft Research based in Montréal, Canada</strong></p>

			    <p><strong>Title</strong>: Bias and Beyond: On Generative AI and the Future of Search and Society</p>

             <p><strong>Abstract</strong>: Robust access to reliable information is a key societal need. In this context, information retrieval (IR) research has responsibilities towards ensuring social good. Recognizing this responsibility, in recent years the IR community has engaged in research on concerns such as fairness and transparency in the context of information access. Emerging technologies such as generative AI is having transformative impact on IR today. However, the sociotechnical implications of employing these technologies in information access go far beyond concerns of bias and fairness. This raises concerns of how we should frame and conceptualize these potential consequences and risks through a sociotechnical lens.

              In this talk, we will deliberate on the sociotechnical implications of generative AI for information access. We will argue that there is both a critical necessity and an exciting opportunity for the IR community to re-center our research agendas on societal needs while dismantling the artificial separation between the work on fairness, accountability, transparency, and ethics in IR and the rest of IR research. Instead of adopting a reactionary strategy of trying to mitigate potential social harms from emerging technologies, the community should aim to proactively set the research agenda for the kinds of systems we should build inspired by diverse explicitly stated sociotechnical imaginaries. The sociotechnical imaginaries that underpin the design and development of information access technologies needs to be explicitly articulated, and we need to develop theories of change in context of these diverse perspectives. Our guiding future imaginaries must be informed by other academic fields, such as democratic theory and critical theory, and should be co-developed with social science scholars, legal scholars, civil rights and social justice activists, and artists, among others.</p>

             <p><strong>Short Bio</strong>: Bhaskar Mitra is a Principal Researcher at Microsoft Research based in Montréal, Canada. His research focuses on AI-mediated information and knowledge access and questions of fairness and ethics in the context of these sociotechnical systems. He is interested in evaluation and benchmarking, and co-organized the MS MARCO ranking leaderboards, the TREC Deep Learning Track (2019-2023), and the TREC Tip-of-the-Tongue Track (2023-2024). Before joining Microsoft Research, he worked on search technologies at Bing for 15+ years. He received his Ph.D. in Computer Science from University College London.</p>

          </br></br>

          <p style="text-align: center;"><img src="./img/image001.png" class="img-rounded" alt="Nil-Jana Akpinar" style=" width: 30%;"></p>

          <p style="text-align: center;">Dr. <strong><a href=" " target="_blank">Nil-Jana Akpinar</a> <br> 
            Amazon Web Services</strong></p>

			      <p><strong>Title</strong>: Bias, Belonging, and the Long-Term Dynamics of Recommender Systems</p>

             <p><strong>Abstract</strong>: Recommender systems are socio-technical systems that actively shape individuals' online experiences by moderating the visibility of news, social media content, and products, thereby influencing preferences, beliefs, and choices. These systems hold significant power to sway public opinion, leading to potential adverse consequences for users and society. In response to calls for greater ethical scrutiny, recent research has focused on measuring and mitigating demographic bias in recommender systems. However, a measurement-construct gap exists between common exposure-based fairness metrics and more intuitive notions of equity for providers and users. This talk will explore how, despite appearing fair in aggregate, common fairness interventions often fail to address the long-term amplification of biases, reflecting a broader challenge of adequately addressing long-term dynamics in ethical recommender system research. Going beyond fairness, we will discuss wider ethical harms of recommender systems and examine the relationship between bias and belonging in social networks, specifically focusing on how recommendation algorithms affect authenticity and exclusion.
             </p>

             <p><strong>Short Bio</strong>: Nil-Jana Akpinar is a Postdoctoral Scientist at Amazon Web Services. Her research lies in Responsible AI with a particular focus on fairness, privacy, and safety in machine learning. Her work takes data and problem-centered perspectives to study impacts of noise, synthetic data, and long-term ethical impacts in algorithms. Prior to joining Amazon, Nil-Jana received her PhD in Statistics and Machine Learning from Carnegie Mellon University where she worked with Alexandra Chouldechova and Zachary Lipton. She is also a recipient of the 2021 Amazon Graduate Research Fellowship.
             </p>
          </br></br>
 
        </div>
      </div>
      
      
      

    </section>

    <!--==========================
    Program Section
    ============================-->
    <section id="program" class="wow fadeInUp section-with-bg">

      <div class="container-fluid">
        <div class="section-header">
          <h2>Program</h2>

          <p>
            The workshop will take place in presence in Washington D.C., USA. The workshop program will be published in June 2024. </strong>. <br> The workshop program is structured as follows.
          </p>
          <!--<p>
            <ul>
              <li>TBC</li>
            </ul>
          </p>-->
          
            <div style="margin: 10px auto 30px auto; width: 50%;">
              <table class="table">
                  <thead>
                  <tr>
                      <th scope="col" class="time" style="min-width: 100px;">Timing</th>
                      <th scope="col">Content</th>
                  </tr>
                  </thead>
                  <tbody>
                  <tr>
                      <th scope="row" class="time"><strong> 09:00 - 09:10</strong></th>
                      <td><strong>Opening remarks</strong></td>
                  </tr>
                  <tr>
                    <th scope="row" class="time"><strong> 09:10 - 10:05</strong></th>
                    <td><strong>Bhaskar Mitra's keynote</strong></td>
                </tr>
                
                 </tr>
                      <tr>
                          <th scope="row" class="time"><strong>10:05 - 10:30 </strong></th>
                          <td>
                              <div style="margin-bottom: 9px;"><strong>Spot thematic session 1 (short introduction) </strong></div>
                              <ul>
                                  <li> An Offer you Cannot Refuse? Trends in the Coerciveness of Amazon Book Recommendations; Jonathan Rystrøm; </br></li>
                              </ul>
                          </td>
                      </tr>
                      <tr>
                          <th scope="row" class="time"><strong>10:30 - 11:00</strong></th>
                          <td><strong>Coffee Break</strong></td>
                      </tr>
                      <tr>
                          <th scope="row" class="time"><strong>11:00 12:30</strong></th>
                          <td>
                              <div style="margin-bottom: 9px;"><strong>Spot thematic session 2 (short introduction)</strong></div>
                              <ul>
                                  <li>Retention Induced Biases in a Recommendation System with Heterogeneous Users; Ma</br></li>
                                  <li>Political Bias of Large Language Models in Few-shot News Summarization; Takeshi Onishi and James Caverlee </br></li>
                                  <li>Fairness Analysis of Machine Learning-Based Code Reviewer Recommendation; Mohajer, Belle, Harzevili, Wang, Hemmati, Wang and Jiang </br></li>
                              </ul>
                          </td>
                      </tr>
                      <tr>
                          <th scope="row" class="time"><strong>12:30 13:30</strong></th>
                          <td><strong>Lunch Break</strong></td>
                      </tr>
                      
                      <tr>
                          <th scope="row" class="time"><strong>13:30 15:00</strong></th>
                          <td>
                              <div style="margin-bottom: 9px;"><strong>Spot thematic session 3 (short introduction)</strong></div>
                              <ul>
                                  <li>Bias Reduction in Social Networks through Agent-Based Simulations; Bartley, Burghardt and Lerman</br></li>
                                  <li>vivaFemme: Mitigating Gender Bias in Neural Team Recommendation via Female-Advocate Loss Regularization; Moasses, Rajaei, Loghmani, Saeedi and Fani </br></li>
                                  <li>Simultaneous Unlearning of Multiple Protected User Attributes From Variational Autoencoder Recommenders Using Adversarial Training; Escobedo, Ganhör, Brandl, Augstein and Schedl </br></li>
                                  
                              </ul>
                          </td>
                      </tr>
                      <tr>
                          <th scope="row" class="time"><strong>15:00 15:30</strong></th>
                          <td><strong>Coffee Break</strong></td>
                      </tr>
                      <tr>
                          <th scope="row" class="time"><strong>15:30 16:25</strong></th>
                          <td><strong>Nil-Jana Akpinar's keynote</strong></td>
                      </tr>
                      <tr>
                          <th scope="row" class="time"><strong>16:25 17:00</strong></th>
                          <td><strong>Discussion and concluding remarks</strong></td>
                      </tr> 
                     
                      </tbody>
                  </table>
              </div>

        </div>
      </div>

    </section>

    <!--==========================
    Committee Section
    ============================-->
    <section id="committee" class="wow fadeInUp">

      <div class="container-fluid">
        <div class="section-header">
          <h2>Organization</h2>
          <p><strong>Workshop Chairs</strong></p>
          <ul>
            <li><a href="https://portalcientifico.uam.es/es/ipublic/researcher/261320" target="_blank">Alejandro Bellogin </a>, Universidad Autonoma de Madrid (Spain)</li>
            <li><a href="https://www.ludovicoboratto.com/" target="_blank">Ludovico Boratto</a>, University of Cagliari (Italy)</li>
            <li><a href="http://www.cycat.io/team/styliani-kleanthous/" target="_blank">Styliani Kleanthous</a>, Open University of Cyprus (Cyprus)</li>
            <li><a href="https://elisabethlex.info" target="_blank">Elisabeth Lex</a>, Graz University of Technology (Austria)</li>
            <li><a href="https://web.unica.it/unica/page/it/francescam_malloci" target="_blank">Francesca Maridina Malloci</a>, University of Cagliari (Italy)</li>
            <li><a href="https://www.mirkomarras.com/" target="_blank">Mirko Marras</a>, University of Cagliari (Italy)</li>
 
          </ul>
          <p><strong>Program Committee</strong></p>
            <ul>
              <li>Ash Ashokan, University of Nebraska Omaha, USA</li>
              <li>Giacomo Balloccu, University of Cagliari, Italy</li>
              <li>Timo Breuer, TH Köln, Germany</li>
              <li>Iván Cantador, Universidad Autónoma de Madrid, Spain</li>
              <li>James Caverlee, Texas A&M University, USA</li>
              <li>Yashar Deldjoo, Polytechnic University of Bari, Italy</li>
              <li>Giorgio Maria Di Nunzio, University of Padua, Italy</li>
              <li>Hossein Fani, University of Windsor, Canada</li>
              <li>Saeed Farzi, K. N. Toosi University of Technology, Iran</li>
              <li>Alireza Gharahighehi, ITEC - KU Leuven, Belgium</li>
              <li>Fabian Haak, TH Köln, Germany</li>
              <li>Toshihiro Kamishima, Independent, Japan</li>
              <li>Aonghus Lawlor, University College Dublin, Ireland</li>
              <li>Cataldo Musto, University of Bari Aldo Moro, Italy</li>
              <li>Marinella Petrocchi, IIT-CNR, Italy</li>
              <li>Erasmo Purificato, Otto von Guericke Univ. Magdeburg, Germany</li>
              <li>Dimitris Sacharidis, Université Libre de Bruxelles, Belgium</li>
              <li>Philipp Schaer, TH Köln, Germany</li>
              <li>Manel Slokom, Delft University of Technology, The Netherlands</li>
              <li>Damiano Spina, RMIT University, Australia</li>
              <li>Gian Antonio Susto, University of Padova, Italy</li>
              <li>Marko Tkalcic, University of Primorska, Slovenia</li>
              <li>Antonela Tommasel, ISISTAN CONICET-UNCPBA, Argentina</li>
              <li>Helma Torkamaan, Delft University of Technology, The Netherlands</li>
              <li>João Vinagre, Joint Research Centre Eu. Commission, Italy</li>
              <li>Emine Yilmaz, Amazon, UK</li>
              <li>Eva Zangerle, University of Innsbruck, Austria</li>
            </ul>    
        </div>
      </div>

    </section>

      <!--==========================
    Attending Section
    ============================-->
    <section id="attending" class="wow fadeInUp section-with-bg">

      <div class="container-fluid">
        <div class="section-header">
          <h2>Register</h2>
          <p>Please register from the  SIGIR 2024's main conference website following the instructions indicated at <a href="https://sigir-2024.github.io/attend_registration.html" target="_blank">https://sigir-2024.github.io/attend_registration.html</a>.</p>
        </div>
      </div>

    </section>

    <!--==========================
    Past Editions Section
    ============================-->
    <section id="editions" class="wow fadeInUp">

      <div class="container-fluid">
        <div class="section-header">
			<h2>Related Workshops</h2>
			<p>We also invite you to check out the three related workshops:</p>
			<ul>
        <li><a href="https://biasinrecsys.github.io/ecir2023/" target="_blank">4th International Workshop on Algorithmic Bias in Search and Recommendation (Bias@ECIR2023) </a></li>
				<li><a href="http://biasinrecsys.github.io/ecir2022/" target="_blank">3rd International Workshop on Algorithmic Bias in Search and Recommendation (Bias@ECIR2022)</a></li>
				<li><a href="http://biasinrecsys.github.io/ecir2021/" target="_blank">2nd International Workshop on Algorithmic Bias in Search and Recommendation (Bias@ECIR2021)</a></li>
				<li><a href="http://bias.disim.univaq.it/" target="_blank">1st International Workshop on Algorithmic Bias in Search and Recommendation (Bias@ECIR2020)</a></li>
			</ul>
        </div>
      </div>

    </section>

    <!--==========================
    Contacts Section
    ============================-->
    <section id="contacts" class="wow fadeInUp section-with-bg">

      <div class="container-fluid">
        <div class="section-header">
          <h2>Contacts</h2>
          <p>For general enquiries on the workshop, please send an email to <strong>alejandro.bellogin@uam.es</strong>, <strong>ludovico.boratto@acm.org</strong>, <strong>s.kleanthous@cyens.org.cy</strong>,
            <strong>elisabeth.lex@tugraz.at</strong>, <strong>francescam.malloci@unica.it</strong>, <strong>mirko.marras@acm.org</strong>.</p>
          </br>
        </div>
      </div>
    </section>

    <!--==========================
    Acks Section
    ============================-->
   <!--
    <section id="acknowledgments" class="wow fadeInUp">

      <div class="container-fluid">
        <div class="section-header">
          <h2>Acknowledgements</h2>
          <div class="row" style="margin: 10px auto 30px auto;width: 50%;">
            <div class="col">
              <img src="img/cagliari.png" alt="cagliari" style="width: 100%;">
            </div>
            <div class="col">
              <img src="img/sapienza.png" alt="sapienza" style="width: 100%;">
            </div>
            <div class="col">
              <img src="img/aquila.png" alt="aquila" style="width: 100%;">
            </div>
          </div>
          <div class="row" style="margin: 10px auto 30px auto;width: 50%;">
            <div class="col">
              <img src="img/sobigdata.png" alt="sobigdata" style="width: 100%;">
            </div>
            <div class="col">
              <img src="img/springer.png" alt="springer" style="width: 100%;">
            </div>
          </div>
	  <p>The "Fourth International Workshop on Algorithmic Bias in Search and Recommendation (Bias 2023)" event was organised as part of the SoBigData.it project (Prot. IR0000013 - Call n. 3264 of 12/28/2021) initiatives aimed at training new users and communities in the usage of the research infrastructure (SoBigData.eu). 
SoBigData.it receives funding from European Union – NextGenerationEU – National Recovery and Resilience Plan (Piano Nazionale di Ripresa e Resilienza, PNRR) – Project: “SoBigData.it – Strengthening the Italian RI for Social Mining and Big Data Analytics” – Prot. IR0000013 – Avviso n. 3264 del 28/12/2021.</p>	
        </div>
      </div>
    </section>

   --> 

  </main>

  <a href="#" class="back-to-top"><i class="fa fa-angle-up"></i></a>

  <!-- JavaScript Libraries -->
  <script src="lib/jquery/jquery.min.js"></script>
  <script src="lib/jquery/jquery-migrate.min.js"></script>
  <script src="lib/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="lib/easing/easing.min.js"></script>
  <script src="lib/superfish/hoverIntent.js"></script>
  <script src="lib/superfish/superfish.min.js"></script>
  <script src="lib/wow/wow.min.js"></script>
  <script src="lib/venobox/venobox.min.js"></script>
  <script src="lib/owlcarousel/owl.carousel.min.js"></script>

  <!-- Contact Form JavaScript File -->
  <script src="contactform/contactform.js"></script>

  <!-- Template Main Javascript File -->
  <script src="js/main.js"></script>
</body>

</html>
